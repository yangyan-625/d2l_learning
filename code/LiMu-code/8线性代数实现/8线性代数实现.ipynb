{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0b8610-dfd8-4c0a-baf4-3770e044bcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.])\n",
      "tensor([2.])\n",
      "tensor([8.])\n",
      "tensor([2.])\n",
      "tensor([16.])\n"
     ]
    }
   ],
   "source": [
    "# 标量由只有一个元素的张量表示\n",
    "import torch\n",
    "x = torch.tensor([4.0])\n",
    "y = torch.tensor([2.0])\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(x ** y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d46112-3fa8-46d4-adc5-8a895ae3a9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============一维向量a===========\n",
      "\n",
      "torch.Size([1])\n",
      "1\n",
      "tensor([2.3000])\n",
      "==============一维向量b===========\n",
      "\n",
      "torch.Size([3])\n",
      "tensor([1.2000, 4.5000, 9.0000])\n",
      "1\n",
      "=============随机标量c============\n",
      "\n",
      "torch.Size([])\n",
      "tensor(0.1961)\n",
      "0\n",
      "0.1960923820734024\n",
      "============标量d================\n",
      "\n",
      "torch.Size([])\n",
      "0\n",
      "8.800000190734863\n"
     ]
    }
   ],
   "source": [
    "# 注意区分张量中：只有一个元素的一维向量、一个标量\n",
    "import torch\n",
    "a = torch.tensor([2.3])\n",
    "print('==============一维向量a===========\\n')\n",
    "print(a.shape)\n",
    "print(a.dim())\n",
    "print(a)\n",
    "\n",
    "b = torch.tensor([1.2, 4.5, 9])\n",
    "print('==============一维向量b===========\\n')\n",
    "print(b.shape)\n",
    "print(b)\n",
    "print(b.dim())\n",
    "\n",
    "c = torch.randn(size=())\n",
    "print('=============随机标量c============\\n')\n",
    "print(c.shape)\n",
    "print(c)\n",
    "print(c.dim())\n",
    "print(c.item())\n",
    "\n",
    "d = torch.tensor(8.8)\n",
    "print('============标量d================\\n')\n",
    "print(d.shape)  # 形状\n",
    "print(d.dim())  # 维度总数\n",
    "print(d.item()) # 获取python标量值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fa3490-9c59-4ddf-b0b3-0876bfda8a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将向量视为标量值组成的列表\n",
    "x = torch.arange(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ee5820c-51c9-418e-abcd-875261378f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过张量的索引来访问任一元素\n",
    "a = x[2]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56464314-f7ed-4c80-82cd-c19a58b7314a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量长度\n",
      " 5\n",
      "张量形状\n",
      " torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print('张量长度\\n',len(x))\n",
    "print('张量形状\\n', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b25f5d-2d2c-46af-99e2-3bb406833a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]),\n",
       " tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过指定两个分量m和n来创建一个形状为m*n的矩阵\n",
    "A = torch.ones(4,5)\n",
    "B = torch.arange(12).reshape(3,4)\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb646b6-5d24-47ef-a808-de429c32edd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[ 0,  4,  8],\n",
      "        [ 1,  5,  9],\n",
      "        [ 2,  6, 10],\n",
      "        [ 3,  7, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵的转置\n",
    "A_T = A.T\n",
    "print(A_T)\n",
    "print(B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "374af6e6-e284-48ef-9145-89a27e86503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]]),\n",
       " tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以构建更多轴的数据结构\n",
    "A = torch.ones(2, 3, 4)\n",
    "B = torch.arange(24).reshape(2, 3, 4)\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0afd62a-e1de-4798-847d-0d719a40a57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 相同形状的任何两个张量，按元素二元运算的结果都将是相同形状的张量\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone()  # 通过分配新内存，将A的一个副本分配给B\n",
    "A, A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c43761bf-10f5-43c0-b552-714e4bef767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方法1：\n",
      " tensor([[  0.,   1.,   4.,   9.],\n",
      "        [ 16.,  25.,  36.,  49.],\n",
      "        [ 64.,  81., 100., 121.],\n",
      "        [144., 169., 196., 225.],\n",
      "        [256., 289., 324., 361.]])\n",
      "方法2：\n",
      " tensor([[  0.,   1.,   4.,   9.],\n",
      "        [ 16.,  25.,  36.,  49.],\n",
      "        [ 64.,  81., 100., 121.],\n",
      "        [144., 169., 196., 225.],\n",
      "        [256., 289., 324., 361.]])\n",
      "方法3：\n",
      " tensor([[  0.,   1.,   4.,   9.],\n",
      "        [ 16.,  25.,  36.,  49.],\n",
      "        [ 64.,  81., 100., 121.],\n",
      "        [144., 169., 196., 225.],\n",
      "        [256., 289., 324., 361.]])\n"
     ]
    }
   ],
   "source": [
    "# 两个矩阵按元素相乘：哈达玛积\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone()  # 通过分配新内存，将A的一个副本分配给B\n",
    "print('方法1：\\n', A * B)\n",
    "print('方法2：\\n', torch.mul(A, B))\n",
    "print('方法3：\\n', torch.multiply(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce6986bf-d70b-4f91-87bd-3589943a92d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个标量与一个矩阵相加\n",
      " tensor([[[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]],\n",
      "\n",
      "        [[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]]])\n",
      "一个标量与一个矩阵相乘\n",
      " tensor([[[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个标量与一个矩阵相加，一个标量与一个矩阵相乘\n",
    "x = 2\n",
    "A_ = torch.ones(2, 3, 4)\n",
    "print('一个标量与一个矩阵相加\\n', x + A_)\n",
    "print('一个标量与一个矩阵相乘\\n', x * A_)\n",
    "(x * A_).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb960885-3fdd-4443-837e-28328ae7d559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算张量元素的和，和是一个标量\n",
    "x = torch.arange(4, dtype=torch.float32).reshape(2,2)\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "151fec39-ebc1-4866-b926-583424e68d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      " tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5],\n",
      "         [ 6,  7]],\n",
      "\n",
      "        [[ 8,  9],\n",
      "         [10, 11],\n",
      "         [12, 13],\n",
      "         [14, 15]],\n",
      "\n",
      "        [[16, 17],\n",
      "         [18, 19],\n",
      "         [20, 21],\n",
      "         [22, 23]]])\n",
      "按第一个轴求和\n",
      " tensor([[24, 27],\n",
      "        [30, 33],\n",
      "        [36, 39],\n",
      "        [42, 45]])\n",
      "按第二个轴求和\n",
      " tensor([[12, 16],\n",
      "        [44, 48],\n",
      "        [76, 80]])\n",
      "按第三个轴求和\n",
      " tensor([[ 1,  5,  9, 13],\n",
      "        [17, 21, 25, 29],\n",
      "        [33, 37, 41, 45]])\n"
     ]
    }
   ],
   "source": [
    "# 指定一个轴求和，结果是剩下轴的形状\n",
    "A = torch.arange(24).reshape(3, 4, 2)\n",
    "print('A\\n', A)\n",
    "print('按第一个轴求和\\n', A.sum(axis=0))\n",
    "print('按第二个轴求和\\n', A.sum(axis=1))\n",
    "print('按第三个轴求和\\n', A.sum(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6b087c8-a3e5-4274-9ef8-673ac590bfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按第一个轴和第二个轴求和\n",
      " tensor([132., 144.])\n",
      "按第一个轴和第三个轴求和\n",
      " tensor([51., 63., 75., 87.])\n",
      "按第二个轴和第三个轴求和\n",
      " tensor([ 28.,  92., 156.])\n"
     ]
    }
   ],
   "source": [
    "# 指定两个轴求和，结果是剩下轴的形状\n",
    "A = torch.arange(24, dtype=torch.float32).reshape(3, 4, 2)\n",
    "print('按第一个轴和第二个轴求和\\n', A.sum(axis=[0, 1]))\n",
    "print('按第一个轴和第三个轴求和\\n', A.sum(axis=[0, 2]))\n",
    "print('按第二个轴和第三个轴求和\\n', A.sum(axis=[1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2c7079a-bca9-4e5f-8914-b3a0e04063cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方法1：\n",
      " tensor(1.5000)\n",
      "方法2：\n",
      " tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "# 求平均值\n",
    "A = torch.arange(4, dtype=torch.float32).reshape(2, 2)\n",
    "print('方法1：\\n', A.mean())\n",
    "print('方法2：\\n', A.sum() / A.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14b0acad-6c6c-4ccc-8c53-21f82f2cc2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按特定轴求平均值\n",
    "A.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35d0bb7f-319f-4da0-98b8-50dbebe4a1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算总和时保持轴数不变：\n",
      " tensor([[[ 4.,  6.,  8., 10.]],\n",
      "\n",
      "        [[20., 22., 24., 26.]],\n",
      "\n",
      "        [[36., 38., 40., 42.]]])\n",
      "计算总和时轴数改变：\n",
      " tensor([[ 4.,  6.,  8., 10.],\n",
      "        [20., 22., 24., 26.],\n",
      "        [36., 38., 40., 42.]])\n",
      "计算均值时保持轴数不变：\n",
      " tensor([[[ 2.,  3.,  4.,  5.]],\n",
      "\n",
      "        [[10., 11., 12., 13.]],\n",
      "\n",
      "        [[18., 19., 20., 21.]]])\n",
      "计算均值时轴数改变：\n",
      " tensor([[ 2.,  3.,  4.,  5.],\n",
      "        [10., 11., 12., 13.],\n",
      "        [18., 19., 20., 21.]])\n"
     ]
    }
   ],
   "source": [
    "# 计算总和或均值时保持轴数不变\n",
    "A = torch.arange(24, dtype=torch.float32).reshape(3, 2, 4)\n",
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A_temp = A.sum(axis=1)\n",
    "print('计算总和时保持轴数不变：\\n', sum_A)\n",
    "print('计算总和时轴数改变：\\n', sum_A_temp)\n",
    "print('计算均值时保持轴数不变：\\n', A.mean(axis=1, keepdims=True))\n",
    "print('计算均值时轴数改变：\\n', A.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b34271c-be4c-4923-8ea0-260c06b02c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "按第一个轴累积求和\n",
      " tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [12., 15., 18., 21.]])\n"
     ]
    }
   ],
   "source": [
    "# 按特定轴累加求和\n",
    "B = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "print(B)\n",
    "print('按第一个轴累积求和\\n', B.cumsum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e448b2c0-bb9f-4a7c-82e8-0bf57af41d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.]) tensor([1., 1., 1., 1.]) tensor([2., 5., 1., 3.])\n",
      "向量a和向量b的点积\n",
      " tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "# 两个一维张量是两个向量，计算这两个向量的点积\n",
    "a = torch.arange(4, dtype=torch.float32)\n",
    "b = torch.ones(4, dtype=torch.float32)\n",
    "c = torch.tensor([2.0, 5, 1, 3])\n",
    "print(a, b, c)\n",
    "print('向量a和向量b的点积\\n', torch.dot(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0fb1f774-f4a6-4345-b663-24f8923e4d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([4])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]]) tensor([0., 1., 2., 3.])\n",
      "矩阵A与向量x相乘\n",
      " tensor([14., 38., 62.])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵与向量相乘\n",
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "print(A.shape, x.shape)\n",
    "print(A, x)\n",
    "print('矩阵A与向量x相乘\\n', torch.mv(A, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5b52ca2-4752-4736-a4cc-4221fdf6bffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵A和矩阵B相乘\n",
      " tensor([[ 70.,  76.,  82.,  88.,  94.],\n",
      "        [190., 212., 234., 256., 278.],\n",
      "        [310., 348., 386., 424., 462.]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵与矩阵相乘\n",
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "B = torch.arange(20, dtype=torch.float32).reshape(4, 5)\n",
    "print('矩阵A和矩阵B相乘\\n', torch.mm(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e675bb-d795-4bfb-aaa6-8291018c0057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "B=\n",
      " tensor([[1., 5., 2.],\n",
      "        [4., 2., 8.]])\n",
      "C=\n",
      " tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "加法:\n",
      " tensor([[2., 6., 3.],\n",
      "        [5., 3., 9.]])\n",
      "减法:\n",
      " tensor([[ 0., -4., -1.],\n",
      "        [-3., -1., -7.]])\n",
      "逐元素乘法:\n",
      " tensor([[1., 5., 2.],\n",
      "        [4., 2., 8.]])\n",
      "逐元素除法:\n",
      " tensor([[1.0000, 0.2000, 0.5000],\n",
      "        [0.2500, 0.5000, 0.1250]])\n",
      "矩阵乘法:\n",
      " tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "A 的转置: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "重塑为向量: tensor([1., 1., 1., 1., 1., 1.])\n",
      "重塑形状: tensor([[1., 1., 1., 1., 1., 1.]])\n",
      "原始形状: torch.Size([3, 4])\n",
      "增加维度: torch.Size([1, 3, 4])\n",
      "减少维度: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵的各种运算\n",
    "A = torch.ones(2, 3)\n",
    "B = torch.tensor([[1.0, 5, 2], [4, 2, 8]])\n",
    "C = torch.ones(3, 2)\n",
    "print('A=\\n', A)\n",
    "print('B=\\n', B)\n",
    "print('C=\\n', C)\n",
    "\n",
    "# 基本运算\n",
    "print(\"加法:\\n\", A + B)\n",
    "print(\"减法:\\n\", A - B)\n",
    "print(\"逐元素乘法:\\n\", A * B)  # 或 torch.mul(A, B)\n",
    "print(\"逐元素除法:\\n\", A / B)  # 或 torch.div(A, B)\n",
    "print(\"矩阵乘法:\\n\", A @ C)    # 或 torch.matmul(A, C)\n",
    "\n",
    "# 转置\n",
    "print(\"A 的转置:\", A.T)  # 或 A.t(), torch.transpose(A, 0, 1)\n",
    "\n",
    "# 重塑\n",
    "print(\"重塑为向量:\", A.flatten())  # 或 A.reshape(-1)\n",
    "print(\"重塑形状:\", A.reshape(1, 6))\n",
    "\n",
    "# 改变维度\n",
    "D = torch.arange(12).reshape(3, 4)\n",
    "print(\"原始形状:\", D.shape)\n",
    "print(\"增加维度:\", D.unsqueeze(0).shape)  # [1, 3, 4]\n",
    "print(\"减少维度:\", D.squeeze().shape)     # 移除所有大小为1的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb68e8a9-239a-4f0f-87d8-1690edc12829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量a的L2范数\n",
      " tensor(5.4772)\n"
     ]
    }
   ],
   "source": [
    "# L2范数是向量元素平方和的平方根\n",
    "a = torch.arange(5, dtype=torch.float32)\n",
    "print('向量a的L2范数\\n', torch.norm(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b954c3d4-0ea3-44f3-aaf3-bb7fab9c5ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量b的L1范数\n",
      " tensor(12.)\n"
     ]
    }
   ],
   "source": [
    "# L1范数是向量元素的绝对值之和\n",
    "b = torch.tensor([1.0, -8, 3])\n",
    "print('向量b的L1范数\\n', torch.abs(b).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd7163a4-85a2-4c39-a6a8-5241f2ff8eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵A的F范数：\n",
      " tensor(22.4944)\n"
     ]
    }
   ],
   "source": [
    "# F范数是矩阵的弗罗贝尼乌斯范数，是矩阵元素的平方和的平方根\n",
    "A = torch.arange(12, dtype=torch.float32).reshape(3, 4)\n",
    "print('矩阵A的F范数：\\n', torch.norm(A))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
